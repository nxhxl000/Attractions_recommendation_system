import pandas as pd
import numpy as np
from sklearn.feature_extraction import DictVectorizer
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
import os
from sqlalchemy import create_engine
from dotenv import load_dotenv

# -------------------------
# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
# -------------------------
load_dotenv()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env

DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL:
    raise RuntimeError(
        "DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ .env (—Ñ–æ—Ä–º–∞—Ç: postgresql+psycopg2://...)?sslmode=require"
    )

engine = create_engine(DATABASE_URL, pool_pre_ping=True)

# -------------------------
# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
# -------------------------
def get_data_from_db():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    query = """
    SELECT 
        id,
        name,
        COALESCE(city, '') as city,
        COALESCE(type, '') as type,
        COALESCE(transport, '') as transport,
        COALESCE(price, '') as price,
        COALESCE(working_hours, '') as working_hours,
        COALESCE(rating, 0.0) as rating,
        COALESCE(image_url, '') as image_url
    FROM public.attractions
    """
    try:
        df = pd.read_sql(query, engine)
        return df
    except Exception as e:
        # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç, –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {e}")
        print("–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏...")
        query_simple = "SELECT * FROM public.attractions"
        df = pd.read_sql(query_simple, engine)
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        required_columns = ['name', 'city', 'type', 'transport', 'price', 'working_hours', 'rating']
        for col in required_columns:
            if col not in df.columns:
                if col == 'rating':
                    df[col] = 0.0
                else:
                    df[col] = ''
        return df
    
def get_visited_rated_ids(user_id: int) -> list[int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ attraction_id, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –ø–æ—Å–µ—Ç–∏–ª –∏ –æ—Ü–µ–Ω–∏–ª
    (evaluated = true).
    """
    query = """
        SELECT attraction_id
        FROM public.planned_visits
        WHERE user_id = %(user_id)s
          AND evaluated = TRUE
    """
    df_ids = pd.read_sql(query, engine, params={"user_id": user_id})
    return df_ids["attraction_id"].tolist()    

df = get_data_from_db()

# -------------------------
# –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–æ–ª–µ–π –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏
# -------------------------
def transport_tokens(transport_str):
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
    return [t.strip().lower() for t in transport_str.replace(',', ' ').split()]

def type_tokens(type_str):
    return [t.strip().lower() for t in type_str.replace(',', ' ').split()]

def parse_working_hours_flag(wh_str, desired_period):
    # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –æ—Ç–∫—Ä—ã—Ç–æ –ª–∏ –æ–±—ä–µ–∫—Ç –≤ –Ω—É–∂–Ω—ã–π –ø–µ—Ä–∏–æ–¥.
    # desired_period: 'morning', 'afternoon', 'evening', 'night', 'anytime'
    s = wh_str.lower()
    if '–∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ' in s or '–∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ' in wh_str.lower():
        return 1
    if desired_period == 'anytime':
        return 1
    # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω —á–∞—Å–æ–≤ –≤–∏–¥–∞ "10:00-17:00"
    try:
        if '-' in s:
            a,b = s.split('-')
            h1 = int(a.split(':')[0])
            h2 = int(b.split(':')[0])
            # normalize to 0..23, assume h2 > h1 (simplify)
            if desired_period == 'morning': # 6..11
                return int(not (h2 < 6 or h1 > 11))
            if desired_period == 'afternoon': # 12..16
                return int(not (h2 < 12 or h1 > 16))
            if desired_period == 'evening': # 17..21
                return int(not (h2 < 17 or h1 > 21))
            if desired_period == 'night': # 22..5 -> hard, treat as closed if range doesn't include night hours
                return int((h1 <= 23 and h2 >= 22) or (h1 <= 5))
    except Exception:
        return 0
    return 0

# -------------------------
# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤
# -------------------------
def item_to_feature_dict(row, desired_period):
    d = {}
    # categorical multi-token fields -> one-hot tokens
    for t in transport_tokens(row['transport']):
        d[f"transport={t}"] = 1
    for t in type_tokens(row['type']):
        d[f"type={t}"] = 1
    d[f"price={row['price'].lower()}"] = 1
    d[f"city={row['city'].lower()}"] = 1
    # rating as numeric (will be scaled)
    d["rating"] = row.get("rating", 0.0)
    # working_hours match flag
    d["open_in_period"] = parse_working_hours_flag(row.get("working_hours",""), desired_period)
    return d

# -------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
# -------------------------
def recommend_cosine(df, user_preferences, top_k=5, exclude_ids=None):
    """
    df - DataFrame with columns: id, name, city, type, transport, price, working_hours, rating
    user_preferences - ...
    exclude_ids - —Å–ø–∏—Å–æ–∫ attraction_id, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, —É–∂–µ –ø–æ—Å–µ—â—ë–Ω–Ω—ã–µ –∏ –æ—Ü–µ–Ω—ë–Ω–Ω—ã–µ)
    """
    # üëá —Å–Ω–∞—á–∞–ª–∞ –≤—ã–∫–∏–¥—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –æ–±—ä–µ–∫—Ç—ã
    if exclude_ids:
        df = df[~df["id"].isin(exclude_ids)].copy()

    if df.empty:
        # —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞—Ç—å, –µ—Å–ª–∏ –≤—Å—ë –≤—ã–∫–∏–Ω—É–ª–∏
        df = df.copy()
        df["score"] = np.nan
        return df.head(0)

    desired_period = user_preferences.get("desired_period", "anytime")
    # Build feature dicts for items
    items_features = [item_to_feature_dict(row, desired_period) for _, row in df.iterrows()]
    # Build user feature dict (same tokenization logic)
    user = {
        # city preference (if provided)
    }
    if user_preferences.get("city"):
        user[f"city={user_preferences['city'].lower()}"] = 1
    if user_preferences.get("type"):
        for t in type_tokens(user_preferences["type"]):
            user[f"type={t}"] = 1
    if user_preferences.get("transport"):
        for t in transport_tokens(user_preferences["transport"]):
            user[f"transport={t}"] = 1
    if user_preferences.get("price"):
        user[f"price={user_preferences['price'].lower()}"] = 1
    # rating: use user's minimum rating as a preference (optional)
    user["rating"] = user_preferences.get("min_rating", df['rating'].max())  # prefer higher by default
    # working hours
    user["open_in_period"] = 1  # user wants it open in the chosen period

    # Vectorize dicts
    dv = DictVectorizer(sparse=False)
    X = dv.fit_transform(items_features + [user])  # last row = user
    X_items = X[:-1, :]
    X_user = X[-1, :].reshape(1, -1)

    # Scale rating column to [0,1] to avoid dominating by raw rating
    # find index of 'rating' feature if exists
    feature_names = dv.get_feature_names_out()
    if "rating" in feature_names:
        idx = list(feature_names).index("rating")
        scaler = MinMaxScaler()
        # scale only rating column
        X_items[:, idx:idx+1] = scaler.fit_transform(X_items[:, idx:idx+1])
        X_user[:, idx:idx+1] = scaler.transform(X_user[:, idx:idx+1])

    # Compute cosine similarity
    sims = cosine_similarity(X_items, X_user).reshape(-1)
    df_result = df.copy()
    df_result['score'] = sims
    # Apply optional min_rating filter
    if user_preferences.get("min_rating") is not None:
        df_result = df_result[df_result['rating'] >= user_preferences['min_rating']]
    df_sorted = df_result.sort_values('score', ascending=False).reset_index(drop=True)
    return df_sorted.head(top_k)

# -------------------------
# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# -------------------------
user_prefs = {
    "city": "–ú–æ—Å–∫–≤–∞",
    "type": "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è",
    "transport": "–ü–µ—à–∫–æ–º",
    "price": "–ü–ª–∞—Ç–Ω–æ",
    "desired_period": "night",
    "min_rating": 0.0
}

top = recommend_cosine(df, user_prefs, top_k=10)
print(top[['name', 'city', 'type', 'transport', 'price', 'working_hours', 'rating', 'score']])
